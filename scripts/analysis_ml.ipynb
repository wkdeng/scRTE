{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(ggpubr)\n",
    "library(ggthemes) \n",
    "library(ggplot2)\n",
    "library(ComplexHeatmap)\n",
    "library(circlize)\n",
    "\n",
    "theme_Publication <- function(base_size=20, base_family=\"\") {\n",
    "      library(grid)\n",
    "      library(ggthemes)\n",
    "      (theme_foundation(base_size=base_size, base_family=base_family)\n",
    "       + theme(plot.title = element_text(face = \"bold\",\n",
    "                                         size = rel(1.2), hjust = 0.5),\n",
    "               text = element_text(),\n",
    "               panel.background = element_rect(colour = NA),\n",
    "               plot.background = element_rect(colour = NA),\n",
    "               panel.border = element_rect(colour = NA),\n",
    "               axis.title = element_text(face = \"bold\",size = rel(1)),\n",
    "               axis.title.y = element_text(angle=90,vjust =2),\n",
    "               axis.title.x = element_text(vjust = -0.2),\n",
    "               axis.text = element_text(), \n",
    "               axis.line = element_line(colour=\"black\"),\n",
    "               axis.ticks = element_line(),\n",
    "               panel.grid.major = element_line(colour=\"#f0f0f0\"),\n",
    "               panel.grid.minor = element_blank(),\n",
    "               legend.key = element_rect(colour = NA),\n",
    "               legend.position = \"bottom\",\n",
    "               legend.direction = \"horizontal\",\n",
    "               legend.key.size= unit(0.5, \"cm\"),\n",
    "               legend.margin = unit(0, \"cm\"),\n",
    "#                legend.title = element_text(face=\"italic\"),\n",
    "               plot.margin=unit(c(10,5,5,5),\"mm\"),\n",
    "               strip.background=element_rect(colour=\"#f0f0f0\",fill=\"#f0f0f0\"),\n",
    "               strip.text = element_text(face=\"bold\")\n",
    "          ))\n",
    "      \n",
    "}\n",
    "\n",
    "scale_fill_Publication <- function(...){\n",
    "      library(scales)\n",
    "      discrete_scale(\"fill\",\"Publication\",manual_pal(values = c(\"#386cb0\",\"#fdb462\",\"#7fc97f\",\"#ef3b2c\",\"#662506\",\n",
    "                                                                \"#a6cee3\",\"#fb9a99\",\"#984ea3\",\"#ffff33\",'#6060f4','#ad27ad',\"#386cb0\",\"#fdb462\",\"#7fc97f\",\"#ef3b2c\",\"#662506\",\n",
    "                                                                \"#a6cee3\",\"#fb9a99\",\"#984ea3\",\"#ffff33\",'#6060f4','#ad27ad')), ...)\n",
    "}\n",
    "\n",
    "scale_fill_Publication_continuous <- function(...){\n",
    "      library(scales)\n",
    "      continuous_scale(\"fill\",\"Publication\",manual_pal(values = c(\"#386cb0\",\"#fdb462\",\"#7fc97f\",\"#ef3b2c\",\"#662506\",\n",
    "                                                                \"#a6cee3\",\"#fb9a99\",\"#984ea3\",\"#ffff33\",'#6060f4','#ad27ad')), ...)\n",
    "}\n",
    "\n",
    "scale_colour_Publication <- function(...){\n",
    "      library(scales)\n",
    "      discrete_scale(\"colour\",\"Publication\",manual_pal(values = c(\"#386cb0\",\"#fdb462\",\"#7fc97f\",\"#ef3b2c\",\"#662506\",\n",
    "                                                                  \"#a6cee3\",\"#fb9a99\",\"#984ea3\",\"#ffff33\",'#6060f4','#ad27ad')), ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import scipy\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import scvelo as scv\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "os.chdir('/home/wdeng3/workspace/Codespace/scRTE/scripts/')\n",
    "\n",
    "dataset='../data/all_datasets/AD_HS_00001.cell_exp.txt'\n",
    "rmsk_f='../../universal_data/rmsk/rmsk_GRCh38.txt'\n",
    "dataset_umap='../data/all_datasets/AD_HS_00001.cell_umap.txt'\n",
    "gtf='../../universal_data/ref/GRCh38/gencode.v43.basic.annotation.gtf'\n",
    "input_path='../data/all_datasets/'\n",
    "\n",
    "gene_type={}\n",
    "for line in open(gtf):\n",
    "    if not line.startswith('#'):\n",
    "        info=line.strip().split('\\t')\n",
    "        if info[2]=='gene':\n",
    "            split_='gene_name \"' if 'gene_name' in info[-1] else 'gene_id \"'\n",
    "            gene_name=info[-1].split(split_)[1].split('\"')[0]\n",
    "            if 'lncRNA' in info[-1] :\n",
    "                gene_type[gene_name]='lncRNA'\n",
    "            elif 'protein_coding' in info[-1]:\n",
    "                gene_type[gene_name]='protein_coding'\n",
    "            elif 'pseudogene' in info[-1]:\n",
    "                gene_type[gene_name]='pseudogene'\n",
    "            else:\n",
    "                gene_type[gene_name]='Others'\n",
    "            \n",
    "rmsk=pd.read_csv(rmsk_f,sep='\\t')\n",
    "rmsk['repFamily']=[x.replace('?','') for x in rmsk['repFamily']]\n",
    "rmsk['repLen']=rmsk['genoEnd']-rmsk['genoStart']\n",
    "classification=rmsk.loc[rmsk['repClass'].isin(['SINE', 'LINE', 'LTR']),['repName','repClass','repFamily']].drop_duplicates(ignore_index=True)\n",
    "tmp=rmsk.iloc[:,[10,11]].drop_duplicates()\n",
    "te_cls=dict(zip(tmp['repName'],tmp['repClass']))\n",
    "tmp=rmsk.iloc[:,[10,11,12]].drop_duplicates()\n",
    "tmp=tmp.loc[tmp['repClass'].isin(['SINE','LINE','LTR']),:]\n",
    "te_fam=dict(zip(tmp['repName'],tmp['repFamily']))\n",
    "fam_te=defaultdict(list)\n",
    "for x in te_fam:\n",
    "    fam_te[te_fam[x]].append(x)\n",
    "gene_type.update(te_cls)\n",
    "rtes=rmsk['repName'].unique()\n",
    "\n",
    "genes=list(gene_type.keys())\n",
    "genes_rep=[x.replace('_','.').replace('-','.') for x in genes]\n",
    "file_list=[x for x in os.listdir(input_path) if x.endswith('.cell_exp.txt')]\n",
    "\n",
    "def get_dataset(dataset):\n",
    "    print(f'loading data: {dataset} \\n')\n",
    "    dt_ls=[x for x in file_list if x.startswith(dataset)]\n",
    "    print('Reading %s \\n'%os.path.join(input_path,dt_ls[0]))\n",
    "    cell_exp=pd.read_table(os.path.join(input_path,dt_ls[0]),index_col=0)\n",
    "    if len(dt_ls) >1:\n",
    "        cell_umap=pd.read_table(f'{input_path}/{dataset}.1.cell_umap.txt',index_col=0)\n",
    "        for i in range(1,len(dt_ls)):\n",
    "            print('Reading %s \\n'%os.path.join(input_path,dt_ls[i]))\n",
    "            cell_exp=pd.concat([cell_exp,pd.read_table(f'{input_path}/'+dt_ls[i],index_col=0)])\n",
    "            cell_umap=pd.concat([cell_umap,pd.read_table(f'{input_path}/{dataset}.{i}.cell_umap.txt',index_col=0)])\n",
    "    else:\n",
    "        cell_umap=pd.read_table(f'{input_path}/'+dataset+'.cell_umap.txt',index_col=0)\n",
    "    \n",
    "    cell_umap['predicted.celltype'] = cell_umap['predicted.celltype'].replace(\n",
    "        'Opc', 'OPC')\n",
    "    for i in range(cell_umap.shape[0]):\n",
    "        if cell_umap.iloc[i,1] =='Stage_0':\n",
    "            cell_umap.iloc[i,1]='Control'\n",
    "        if cell_umap.iloc[i,1] !='Control' and  not cell_umap.iloc[i,1].startswith('Stage'):\n",
    "            cell_umap.iloc[i,1]=cell_umap.iloc[i,7].split('_')[0]\n",
    "    \n",
    "    colnames=cell_exp.columns\n",
    "    repl_colnames=[]\n",
    "    for x in colnames:\n",
    "        if '.' not in x or x not in genes_rep:\n",
    "            repl_colnames.append(x)\n",
    "        else:\n",
    "            repl_colnames.append(genes[genes_rep.index(x)])\n",
    "    cell_exp.columns=repl_colnames\n",
    "    print(f'Done loading: {dataset} \\n')\n",
    "    return [cell_exp,dataset,cell_umap]\n",
    "\n",
    "def get_dataset_nomerge(dataset):\n",
    "    print(f'loading data: {dataset} \\n')\n",
    "    cell_exp=pd.read_table(f'{input_path}/{dataset}.cell_exp.txt',index_col=0)\n",
    "    cell_umap=pd.read_table(f'{input_path}/{dataset}.cell_umap.txt',index_col=0)\n",
    "    \n",
    "    cell_umap['predicted.celltype'] = cell_umap['predicted.celltype'].replace(\n",
    "        'Opc', 'OPC')\n",
    "    for i in range(cell_umap.shape[0]):\n",
    "        if cell_umap.iloc[i,1] =='Stage_0':\n",
    "            cell_umap.iloc[i,1]='Control'\n",
    "        if cell_umap.iloc[i,1] !='Control' and  not cell_umap.iloc[i,1].startswith('Stage'):\n",
    "            cell_umap.iloc[i,1]=cell_umap.iloc[i,7].split('_')[0]\n",
    "    \n",
    "    colnames=cell_exp.columns\n",
    "    repl_colnames=[]\n",
    "    for x in colnames:\n",
    "        if '.' not in x or x not in genes_rep:\n",
    "            repl_colnames.append(x)\n",
    "        else:\n",
    "            repl_colnames.append(genes[genes_rep.index(x)])\n",
    "    cell_exp.columns=repl_colnames\n",
    "    print(f'Done loading: {dataset} \\n')\n",
    "    return [cell_exp,dataset,cell_umap]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disease stage inference from RTE expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfg_ad=all_dfs['AD_HS_00003.1'].copy()\n",
    "# sfg_umap=all_cell_umaps['AD_HS_00003.1'].copy()\n",
    "sfg_ad=pd.read_csv('../data/all_datasets/AD_HS_00003.1.cell_exp.txt',sep='\\t',index_col=0)\n",
    "sfg_umap=pd.read_csv('../data/all_datasets/AD_HS_00003.1.cell_umap.txt',sep='\\t',index_col=0)\n",
    "colnames=sfg_ad.columns\n",
    "repl_colnames=[]\n",
    "for x in colnames:\n",
    "    if '.' not in x or x not in genes_rep:\n",
    "        repl_colnames.append(x)\n",
    "    else:\n",
    "        repl_colnames.append(genes[genes_rep.index(x)])\n",
    "sfg_ad.columns=repl_colnames\n",
    "\n",
    "sfg_ad['Diagnosis']=sfg_umap['Diagnosis']\n",
    "sfg_ad['predicted.celltype']=sfg_umap['predicted.celltype']\n",
    "sfg_ad['UMAP_1']=sfg_umap['UMAP_1']\n",
    "sfg_ad['UMAP_2']=sfg_umap['UMAP_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_=sfg_ad.loc[sfg_ad['predicted.celltype']=='Ex',[x for x in sfg_ad.columns if x not in rtes]]\n",
    "adata=anndata.AnnData(X=np.expm1(ex_.iloc[:,:-4]))\n",
    "\n",
    "adata.obs['Diagnosis']=ex_['Diagnosis']\n",
    "adata.obs['CellType']=ex_['predicted.celltype']\n",
    "adata.obsm['X_umap']=ex_[['UMAP_1','UMAP_2']].to_numpy()\n",
    "adata.var[\"mito\"] = adata.var_names.str.startswith(\"MT-\")\n",
    "adata.layers[\"counts\"] = adata.X.copy()\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=[\"mito\"], inplace=True)\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "# fig,axs=plt.subplots(1,3,figsize=[45,8])\n",
    "\n",
    "non_mito=np.invert(adata.var_names.str.startswith(\"MT-\"))\n",
    "adata=adata[:,non_mito]\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "# sc.pl.highly_variable_genes(adata)\n",
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "# sc.pl.pca(adata, color='CellType')\n",
    "sc.tl.rank_genes_groups(adata, 'Diagnosis', method='t-test')\n",
    "sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False)\n",
    "gene_markers=[]\n",
    "marker_list=np.array(adata.uns['rank_genes_groups']['names'].tolist()).flatten()\n",
    "for i in marker_list:\n",
    "    if i not in gene_markers:\n",
    "        gene_markers.append(i)\n",
    "extended_markers=gene_markers[:730*2]\n",
    "gene_markers=gene_markers[:730]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare ML models\n",
    "#### RTE only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell='Ex'\n",
    "cell_exp=sfg_ad.loc[sfg_ad['predicted.celltype']==cell,:]\n",
    "cell_exp.iloc[:,:-4]=np.expm1(cell_exp.iloc[:,:-4].astype(float))\n",
    "rte_exp=cell_exp[[x for x in cell_exp.columns if x in rtes]]\n",
    "factors=pd.factorize(cell_exp['Diagnosis'])\n",
    "labels=factors[0]\n",
    "definitions=factors[1]\n",
    "x_train,x_test,y_train,y_test = train_test_split(rte_exp.to_numpy(),labels,test_size=0.2,random_state=42)\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "names = [\n",
    "    \"RBF SVM\",\n",
    "    \"Random Forest\",\n",
    "    \"AdaBoost\",\n",
    "    \"MLP\"\n",
    "]\n",
    "if not os.path.isfile(f'../data/analysis/models/{names[0]}_RTE.joblib'):\n",
    "    classifiers = [\n",
    "        SVC(decision_function_shape='ovr',random_state=42),\n",
    "        RandomForestClassifier(n_estimators=100,random_state=42),\n",
    "        AdaBoostClassifier(n_estimators=100,random_state=42),\n",
    "        MLPClassifier(alpha=1, max_iter=10000,random_state=42,hidden_layer_sizes=(1000,1000))]\n",
    "    for i in range(len(classifiers)):\n",
    "        cls = classifiers[i]\n",
    "        cls.fit(x_train, y_train)\n",
    "        dump(cls, f'../data/analysis/models/{names[i]}_RTE.joblib')\n",
    "else:\n",
    "    classifiers=[load(f'../data/analysis/models/{names[i]}_RTE.joblib') for i in range(len(names))]\n",
    "\n",
    "# model name, predicted label, true label, count\n",
    "pre_labels=['Stage_0','Stage_2','Stage_6']\n",
    "t_labels=['Stage_6','Stage_2','Stage_0']\n",
    "for i in range(len(classifiers)):\n",
    "    cls = classifiers[i]\n",
    "    name=names[i]\n",
    "    y_pred=cls.predict(x_test)\n",
    "    print(name,accuracy_score(y_test, y_pred),len(labels),len(cell_exp.loc[cell_exp['Diagnosis']=='Stage_0',:]),len(cell_exp.loc[cell_exp['Diagnosis']=='Stage_2',:]),len(cell_exp.loc[cell_exp['Diagnosis']=='Stage_6',:]))\n",
    "    cm=confusion_matrix(y_test,y_pred)\n",
    "    pd.DataFrame(cm,columns=pre_labels,index=pre_labels).to_csv(f'../data/analysis/models/{names[i]}_rte_cm.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "ps<-list()\n",
    "pdf('../data/analysis/figures/rte_cm.pdf')\n",
    "\n",
    "for(name in c(\"RBF SVM\",\"Random Forest\",\"AdaBoost\",\"MLP\")){\n",
    "     print(name)\n",
    "     df<-read.csv(paste0('../data/analysis/models/',name,'_rte_cm.csv'),row.names=1)\n",
    "     p<-Heatmap(df,cluster_columns=F,cluster_rows=F,column_title=\"Predicted label\",column_title_gp = gpar(fontsize = 25),row_title='True label',row_title_gp = gpar(fontsize = 25),\n",
    "          cell_fun = function(j, i, x, y, width, height, fill) {grid.text(sprintf(\"%s\", df[i, j]), x, y, gp = gpar(color='white',fontsize = 20))},\n",
    "          show_column_names = FALSE, col = colorRamp2(c(0,1000,1600), c(\"#44A1F2\", \"#BBEFFF\", \"#D18D93\")),\n",
    "          bottom_annotation = HeatmapAnnotation(text = anno_text(colnames(df), rot=0,just='center',location=0,gp=gpar(fontsize=18))),\n",
    "          show_row_names = FALSE,\n",
    "          heatmap_legend_param=list(title='Count',legend_height=unit(10,'cm'),at=c(0,1000,1600), grid_width = unit(1, \"cm\"),title_gp=gpar(fontsize=18),labels_gp = gpar(fontsize=16)))+\n",
    "          rowAnnotation(text = anno_text(colnames(df), rot=90,just='center', location=0.5,gp=gpar(fontsize=18)))\n",
    "     print(p)\n",
    "}\n",
    "\n",
    "dev.off()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = classifiers[1].feature_importances_\n",
    "importances=pd.Series(importances, index=rte_exp.columns)\n",
    "importances=pd.concat([importances, pd.Series(np.std([tree.feature_importances_ for tree in classifiers[1].estimators_], axis=0),index=rte_exp.columns)], axis=1)\n",
    "importances.columns=['Importance','STD']\n",
    "\n",
    "importances=importances.sort_values(by='Importance',ascending=False)\n",
    "importances_=importances.iloc[:20,:]\n",
    "importances_.to_csv('../data/analysis/rte_importances.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "df<-read.csv('../data/analysis/rte_importances.csv')\n",
    "df$X<-factor(df$X,levels=df$X[order(df$Importance,decreasing=T)])\n",
    "p<-ggplot(data=df,aes(x=X,y=Importance,fill=X))+geom_bar(stat='identity')+theme_Publication()+scale_fill_Publication()+theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position='none')+xlab('RTE')+ylab('Importance')+\n",
    " geom_errorbar(aes(ymin=Importance-STD, ymax=Importance+STD), width=.2,position=position_dodge(.9)) \n",
    "print(p)\n",
    "pdf('../data/analysis/figures/rte_importances.pdf')\n",
    "print(p)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gene only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_exp=cell_exp.loc[:,gene_markers]\n",
    "x_train,x_test,y_train,y_test = train_test_split(gene_exp.to_numpy(),labels,test_size=0.2,random_state=42)\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "if not os.path.isfile(f'../data/analysis/models/{names[0]}_gene.joblib'):\n",
    "    classifiers_gene= [\n",
    "        SVC(decision_function_shape='ovr',random_state=42),\n",
    "        RandomForestClassifier(n_estimators=100,random_state=42),\n",
    "        AdaBoostClassifier(),\n",
    "        MLPClassifier(alpha=1, max_iter=10000,random_state=42,hidden_layer_sizes=(1000,1000))\n",
    "    ]\n",
    "    for i in range(len(classifiers_gene)):\n",
    "        cls = classifiers_gene[i]\n",
    "        cls.fit(x_train, y_train)\n",
    "        dump(cls, f'../data/analysis/models/{names[i]}_gene.joblib')\n",
    "else:\n",
    "    classifiers_gene=[load(f'../data/analysis/models/{names[i]}_gene.joblib') for i in range(len(names))]\n",
    "\n",
    "# model name, predicted label, true label, count\n",
    "pre_labels=['Stage_0','Stage_2','Stage_6']\n",
    "t_labels=['Stage_6','Stage_2','Stage_0']\n",
    "for i in range(len(classifiers_gene)):\n",
    "    cls = classifiers_gene[i]\n",
    "    name=names[i]\n",
    "    y_pred=cls.predict(x_test)\n",
    "    print(name,accuracy_score(y_test, y_pred),len(labels),len(cell_exp.loc[cell_exp['Diagnosis']=='Stage_0',:]),len(cell_exp.loc[cell_exp['Diagnosis']=='Stage_2',:]),len(cell_exp.loc[cell_exp['Diagnosis']=='Stage_6',:]))\n",
    "    cm=confusion_matrix(y_test,y_pred)\n",
    "    pd.DataFrame(cm,columns=pre_labels,index=pre_labels).to_csv(f'../data/analysis/models/{names[i]}_gene_cm.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "ps<-list()\n",
    "pdf('../data/analysis/figures/gene_cm.pdf')\n",
    "\n",
    "for(name in c(\"RBF SVM\",\"Random Forest\",\"AdaBoost\",\"MLP\")){\n",
    "     df<-read.csv(paste0('../data/analysis/models/',name,'_gene_cm.csv'),row.names=1)\n",
    "     p<-Heatmap(df,cluster_columns=F,cluster_rows=F,column_title=\"Predicted label\",column_title_gp = gpar(fontsize = 25),row_title='True label',row_title_gp = gpar(fontsize = 25),\n",
    "             cell_fun = function(j, i, x, y, width, height, fill) {grid.text(sprintf(\"%s\", df[i, j]), x, y, gp = gpar(color='white',fontsize = 20))},\n",
    "             show_column_names = FALSE, col = colorRamp2(c(0,1000,1600), c(\"#44A1F2\", \"#BBEFFF\", \"#D18D93\")),\n",
    "             bottom_annotation = HeatmapAnnotation(text = anno_text(colnames(df), rot=0,just='center',location=0,gp=gpar(fontsize=18))),\n",
    "             show_row_names = FALSE,\n",
    "        heatmap_legend_param=list(title='Count',legend_height=unit(10,'cm'),at=c(0,1000,1600), grid_width = unit(1, \"cm\"),title_gp=gpar(fontsize=18),labels_gp = gpar(fontsize=16)))+\n",
    "        rowAnnotation(text = anno_text(colnames(df), rot=90,just='center', location=0.5,gp=gpar(fontsize=18)))\n",
    "     draw(p)\n",
    "     ps[[length(ps)+1]]<-p\n",
    "#      break\n",
    "}\n",
    "# for(p in ps){\n",
    "#     draw(p)\n",
    "# }\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = classifiers_gene[1].feature_importances_\n",
    "importances=pd.Series(importances, index=gene_exp.columns)\n",
    "importances=pd.concat([importances, pd.Series(np.std([tree.feature_importances_ for tree in classifiers_gene[1].estimators_], axis=0),\n",
    "                                              index=gene_exp.columns)], axis=1)\n",
    "importances.columns=['Importance','STD']\n",
    "\n",
    "importances=importances.sort_values(by='Importance',ascending=False)\n",
    "importances_=importances.iloc[:20,:]\n",
    "importances_.to_csv('../data/analysis/gene_importances.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "df<-read.csv('../data/analysis/gene_importances.csv')\n",
    "df$X<-factor(df$X,levels=df$X[order(df$Importance,decreasing=T)])\n",
    "p<-ggplot(data=df,aes(x=X,y=Importance,fill=X))+geom_bar(stat='identity')+theme_Publication()+scale_fill_Publication()+theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position='none')+xlab('RTE')+ylab('Mean decrease in impurity')+\n",
    " geom_errorbar(aes(ymin=Importance-STD, ymax=Importance+STD), width=.2,position=position_dodge(.9)) \n",
    "print(p)\n",
    "pdf('../data/analysis/figures/gene_importances.pdf')\n",
    "print(p)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Combine gene and RTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_exp=cell_exp.loc[:,[x for x in cell_exp.columns if x in rtes]+gene_markers]\n",
    "x_train,x_test,y_train,y_test = train_test_split(combined_exp.to_numpy(),labels,test_size=0.2,random_state=42)\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "if True:#not os.path.isfile(f'../data/analysis/models/{names[0]}_combined.joblib'):\n",
    "    classifiers_combined= [\n",
    "        SVC(decision_function_shape='ovr',random_state=42),\n",
    "        RandomForestClassifier(n_estimators=100,random_state=42),\n",
    "        AdaBoostClassifier(),\n",
    "        MLPClassifier(alpha=1, max_iter=10000,random_state=42,hidden_layer_sizes=(1000,1000))\n",
    "    ]\n",
    "    for i in range(len(classifiers_combined)):\n",
    "        cls = classifiers_combined[i]\n",
    "        cls.fit(x_train, y_train)\n",
    "        dump(cls, f'../data/analysis/models/{names[i]}_combined.joblib')\n",
    "# else:\n",
    "#     classifiers_combined=[load(f'../data/analysis/models/{names[i]}_combined.joblib') for i in range(len(names))]\n",
    "\n",
    "# model name, predicted label, true label, count\n",
    "pre_labels=['Stage_0','Stage_2','Stage_6']\n",
    "for i in range(len(classifiers_combined)):\n",
    "    cls = classifiers_combined[i]\n",
    "    name=names[i]\n",
    "    y_pred=cls.predict(x_test)\n",
    "    print(name,accuracy_score(y_test, y_pred),len(labels),len(cell_exp.loc[cell_exp['Diagnosis']=='Stage_0',:]),len(cell_exp.loc[cell_exp['Diagnosis']=='Stage_2',:]),len(cell_exp.loc[cell_exp['Diagnosis']=='Stage_6',:]))\n",
    "    cm=confusion_matrix(y_test,y_pred)\n",
    "    pd.DataFrame(cm,columns=pre_labels,index=pre_labels).to_csv(f'../data/analysis/models/{names[i]}_combined_cm.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "ps<-list()\n",
    "pdf('../data/analysis/figures/combined_cm.pdf')\n",
    "\n",
    "for(name in c(\"RBF SVM\",\"Random Forest\",\"AdaBoost\",\"MLP\")){\n",
    "     df<-read.csv(paste0('../data/analysis/models/',name,'_combined_cm.csv'),row.names=1)\n",
    "     p<-Heatmap(df,cluster_columns=F,cluster_rows=F,column_title=\"Predicted label\",column_title_gp = gpar(fontsize = 25),row_title='True label',row_title_gp = gpar(fontsize = 25),\n",
    "             cell_fun = function(j, i, x, y, width, height, fill) {grid.text(sprintf(\"%s\", df[i, j]), x, y, gp = gpar(color='white',fontsize = 20))},\n",
    "             show_column_names = FALSE, col = colorRamp2(c(0,1000,1600), c(\"#44A1F2\", \"#BBEFFF\", \"#D18D93\")),\n",
    "             bottom_annotation = HeatmapAnnotation(text = anno_text(colnames(df), rot=0,just='center',location=0,gp=gpar(fontsize=18))),\n",
    "             show_row_names = FALSE,\n",
    "        heatmap_legend_param=list(title='Count',legend_height=unit(10,'cm'),at=c(0,1000,1600), grid_width = unit(1, \"cm\"),title_gp=gpar(fontsize=18),labels_gp = gpar(fontsize=16)))+\n",
    "        rowAnnotation(text = anno_text(colnames(df), rot=90,just='center', location=0.5,gp=gpar(fontsize=18)))\n",
    "     draw(p)\n",
    "     ps[[length(ps)+1]]<-p\n",
    "#      break\n",
    "}\n",
    "# for(p in ps){\n",
    "#     print(p)\n",
    "# }\n",
    "dev.off()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = classifiers_combined[1].feature_importances_\n",
    "importances=pd.Series(importances, index=combined_exp.columns)\n",
    "importances=pd.concat([importances, pd.Series(np.std([tree.feature_importances_ for tree in classifiers_combined[1].estimators_], axis=0),index=combined_exp.columns)], axis=1)\n",
    "importances.columns=['Importance','STD']\n",
    "\n",
    "importances=importances.sort_values(by='Importance',ascending=False)\n",
    "importances_=importances.iloc[:20,:]\n",
    "importances_.to_csv('../data/analysis/combined_importances.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "df<-read.csv('../data/analysis/combined_importances.csv')\n",
    "df$X<-factor(df$X,levels=df$X[order(df$Importance,decreasing=T)])\n",
    "p<-ggplot(data=df,aes(x=X,y=Importance,fill=X))+geom_bar(stat='identity')+theme_Publication()+scale_fill_Publication()+theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position='none')+xlab('RTE')+ylab('Mean decrease in impurity')+\n",
    " geom_errorbar(aes(ymin=Importance-STD, ymax=Importance+STD), width=.2,position=position_dodge(.9)) \n",
    "print(p)\n",
    "pdf('../data/analysis/figures/combined_importances.pdf')\n",
    "print(p)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use extended gene list (top 730x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_exp=cell_exp.loc[:,extended_markers]\n",
    "x_train,x_test,y_train,y_test = train_test_split(combined_exp.to_numpy(),labels,test_size=0.2,random_state=42)\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "if True:#not os.path.isfile(f'../data/analysis/models/{names[0]}_combined.joblib'):\n",
    "    classifiers_combined= [\n",
    "        SVC(decision_function_shape='ovr',random_state=42),\n",
    "        RandomForestClassifier(n_estimators=100,random_state=42),\n",
    "        AdaBoostClassifier(),\n",
    "        MLPClassifier(alpha=1, max_iter=10000,random_state=42,hidden_layer_sizes=(1000,1000))\n",
    "    ]\n",
    "    for i in range(len(classifiers_combined)):\n",
    "        cls = classifiers_combined[i]\n",
    "        cls.fit(x_train, y_train)\n",
    "        dump(cls, f'../data/analysis/models/{names[i]}_extended.joblib')\n",
    "# else:\n",
    "#     classifiers_combined=[load(f'../data/analysis/models/{names[i]}_combined.joblib') for i in range(len(names))]\n",
    "\n",
    "# model name, predicted label, true label, count\n",
    "pre_labels=['Stage_0','Stage_2','Stage_6']\n",
    "for i in range(len(classifiers_combined)):\n",
    "    cls = classifiers_combined[i]\n",
    "    name=names[i]\n",
    "    y_pred=cls.predict(x_test)\n",
    "    print(name,accuracy_score(y_test, y_pred),len(labels),len(cell_exp.loc[cell_exp['Diagnosis']=='Stage_0',:]),len(cell_exp.loc[cell_exp['Diagnosis']=='Stage_2',:]),len(cell_exp.loc[cell_exp['Diagnosis']=='Stage_6',:]))\n",
    "    cm=confusion_matrix(y_test,y_pred)\n",
    "    pd.DataFrame(cm,columns=pre_labels,index=pre_labels).to_csv(f'../data/analysis/models/{names[i]}_extended_cm.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "pdf('../data/analysis/figures/extended_cm.pdf')\n",
    "# ps<-list()\n",
    "for(name in c(\"RBF SVM\",\"Random Forest\",\"AdaBoost\",\"MLP\")){\n",
    "     print(name)\n",
    "     df<-read.csv(paste0('../data/analysis/models/',name,'_extended_cm.csv'),row.names=1)\n",
    "     p<-Heatmap(df,cluster_columns=F,cluster_rows=F,column_title=\"Predicted label\",column_title_gp = gpar(fontsize = 25),row_title='True label',row_title_gp = gpar(fontsize = 25),\n",
    "             cell_fun = function(j, i, x, y, width, height, fill) {grid.text(sprintf(\"%s\", df[i, j]), x, y, gp = gpar(color='white',fontsize = 20))},\n",
    "             show_column_names = FALSE, col = colorRamp2(c(0,1000,1600), c(\"#44A1F2\", \"#BBEFFF\", \"#D18D93\")),\n",
    "             bottom_annotation = HeatmapAnnotation(text = anno_text(colnames(df), rot=0,just='center',location=0,gp=gpar(fontsize=18))),\n",
    "             show_row_names = FALSE,\n",
    "        heatmap_legend_param=list(title='Count',legend_height=unit(10,'cm'),at=c(0,1000,1600), grid_width = unit(1, \"cm\"),title_gp=gpar(fontsize=18),labels_gp = gpar(fontsize=16)))+\n",
    "        rowAnnotation(text = anno_text(colnames(df), rot=90,just='center', location=0.5,gp=gpar(fontsize=18)))\n",
    "     draw(p)\n",
    "     ps[[length(ps)+1]]<-p\n",
    "}\n",
    "\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = classifiers_combined[1].feature_importances_\n",
    "importances=pd.Series(importances, index=combined_exp.columns)\n",
    "importances=pd.concat([importances, pd.Series(np.std([tree.feature_importances_ for tree in classifiers_combined[1].estimators_], axis=0),index=combined_exp.columns)], axis=1)\n",
    "importances.columns=['Importance','STD']\n",
    "\n",
    "importances=importances.sort_values(by='Importance',ascending=False)\n",
    "importances_=importances.iloc[:20,:]\n",
    "importances_.to_csv('../data/analysis/extended_importances.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "df<-read.csv('../data/analysis/extended_importances.csv')\n",
    "df$X<-factor(df$X,levels=df$X[order(df$Importance,decreasing=T)])\n",
    "p<-ggplot(data=df,aes(x=X,y=Importance,fill=X))+geom_bar(stat='identity')+theme_Publication()+scale_fill_Publication()+theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position='none')+xlab('RTE')+ylab('Mean decrease in impurity')+\n",
    " geom_errorbar(aes(ymin=Importance-STD, ymax=Importance+STD), width=.2,position=position_dodge(.9)) \n",
    "print(p)\n",
    "pdf('../data/analysis/figures/extended_importances.pdf')\n",
    "print(p)\n",
    "dev.off()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
